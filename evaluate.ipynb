{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09506f71-2bec-44bd-8916-00c44edaaa39",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Evaluation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ff9eeab-d540-4514-b9dd-9fe9af614231",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "First insert the command line arguments as dbutils widget parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ac03a9f-b31b-436e-a064-536719577f02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Data params ---\n",
    "dbutils.widgets.text(\"dataset\", \"system_1\")\n",
    "dbutils.widgets.text(\"eval_start\", \"0\")\n",
    "dbutils.widgets.text(\"eval_end\", \"None\")\n",
    "\n",
    "# --- Model params ---\n",
    "dbutils.widgets.text(\"run_name\", \"-1\")\n",
    "\n",
    "# --- Predict params ---\n",
    "dbutils.widgets.text(\"use_cuda\", \"True\")\n",
    "dbutils.widgets.text(\"show_details\", \"True\")\n",
    "dbutils.widgets.text(\"threshold\", \"POT\")\n",
    "# If threshold is set to POT, these are the POT params\n",
    "dbutils.widgets.text(\"use_mov_av\", \"False\")\n",
    "dbutils.widgets.text(\"q\", \"0.001\")\n",
    "dbutils.widgets.text(\"level\", \"0.99\")\n",
    "dbutils.widgets.text(\"dynamic_pot\", \"False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7804629f-baeb-4831-b7ac-745324928f2d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e91f149-7064-49d3-a5b7-014f5974e51a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from architecture import MTAD_GAT\n",
    "from model import Handler\n",
    "from utils import str2bool, str2type\n",
    "from utils import get_run_id, get_data, SlidingWindowDataset, create_data_loader\n",
    "from utils import pot_threshold, json_to_numpy, update_json\n",
    "from utils import get_metrics, PA, calculate_latency\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb07a76a-659a-4b41-ba83-1e1453daa0b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Get the parameters' values and fix them to the correct type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "673629aa-5ba5-4c5e-b863-6809003bdbb6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset = dbutils.widgets.get(\"dataset\")\n",
    "eval_start = int(dbutils.widgets.get(\"eval_start\"))\n",
    "eval_end = str2type(dbutils.widgets.get(\"eval_end\"))\n",
    "\n",
    "run_name = int(dbutils.widgets.get(\"run_name\"))\n",
    "\n",
    "use_cuda = str2type(dbutils.widgets.get(\"use_cuda\"))\n",
    "show_details = str2type(dbutils.widgets.get(\"show_details\"))\n",
    "threshold = dbutils.widgets.get(\"threshold\")\n",
    "use_mov_av = str2type(dbutils.widgets.get(\"use_mov_av\"))\n",
    "q = float(dbutils.widgets.get(\"q\"))\n",
    "level = float(dbutils.widgets.get(\"level\"))\n",
    "dynamic_pot = str2type(dbutils.widgets.get(\"dynamic_pot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "871137c6-e5f2-4d15-a1a3-5b85569a07d6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Make sure the proper container (to draw data from) is mounted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df750dac-d357-4332-9834-093688f95f38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mount already exists.\n"
     ]
    }
   ],
   "source": [
    "# Checking if mount already exists\n",
    "mnts = dbutils.fs.mounts()\n",
    "mnt_exists = False\n",
    "for mount in mnts:\n",
    "    if mount.mountPoint == \"/mnt/datasets\":\n",
    "        mnt_exists = True\n",
    "\n",
    "if mnt_exists == False:\n",
    "    # Setup some parameters and keys\n",
    "    account_name = \"canopuslake\"\n",
    "    container = \"datasets\"\n",
    "\n",
    "    client_secret = dbutils.secrets.get(scope=\"vault_scope\", key=\"dbricks-to-lake-secret\")\n",
    "    client_id = dbutils.secrets.get(scope=\"vault_scope\", key=\"dbricks-to-lake-client-ID\")\n",
    "    tenant_id = dbutils.secrets.get(scope=\"vault_scope\", key=\"dbricks-to-lake-tenant-ID\")\n",
    "\n",
    "    # Define the connection configurations\n",
    "    configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "          \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "          \"fs.azure.account.oauth2.client.id\": client_id,\n",
    "          \"fs.azure.account.oauth2.client.secret\": client_secret,\n",
    "          \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\"}\n",
    "\n",
    "    # Command to mount the blob storage container locally\n",
    "    dbutils.fs.mount(\n",
    "    source = f\"abfss://{container}@{account_name}.dfs.core.windows.net/\",\n",
    "    mount_point = \"/mnt/datasets\",\n",
    "    extra_configs = configs)\n",
    "else:\n",
    "    print(\"Mount already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5806886e-34de-4bc6-95c1-8530d18b5c62",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Finally, run the evaluation script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15f184fd-ab40-4460-ab4e-ace57c155b85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model from run with ID: 0dac450f8b2d4e5294070621318ae72b\nEvaluating:\nThe size of the dataset is: 28479 sample(s).\nCalculating scores on evaluation data...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/112 [00:00<?, ?it/s]\r  1%|          | 1/112 [00:00<00:24,  4.48it/s]\r  2%|▏         | 2/112 [00:00<00:20,  5.35it/s]\r  3%|▎         | 3/112 [00:00<00:19,  5.71it/s]\r  4%|▎         | 4/112 [00:00<00:18,  5.88it/s]\r  4%|▍         | 5/112 [00:00<00:17,  5.99it/s]\r  5%|▌         | 6/112 [00:01<00:17,  6.04it/s]\r  6%|▋         | 7/112 [00:01<00:17,  6.06it/s]\r  7%|▋         | 8/112 [00:01<00:17,  6.08it/s]\r  8%|▊         | 9/112 [00:01<00:16,  6.11it/s]\r  9%|▉         | 10/112 [00:01<00:16,  6.13it/s]\r 10%|▉         | 11/112 [00:01<00:16,  6.15it/s]\r 11%|█         | 12/112 [00:02<00:16,  6.15it/s]\r 12%|█▏        | 13/112 [00:02<00:16,  6.16it/s]\r 12%|█▎        | 14/112 [00:02<00:15,  6.15it/s]\r 13%|█▎        | 15/112 [00:02<00:15,  6.16it/s]\r 14%|█▍        | 16/112 [00:02<00:15,  6.16it/s]\r 15%|█▌        | 17/112 [00:02<00:15,  6.16it/s]\r 16%|█▌        | 18/112 [00:02<00:15,  6.16it/s]\r 17%|█▋        | 19/112 [00:03<00:15,  6.17it/s]\r 18%|█▊        | 20/112 [00:03<00:14,  6.16it/s]\r 19%|█▉        | 21/112 [00:03<00:14,  6.16it/s]\r 20%|█▉        | 22/112 [00:03<00:14,  6.16it/s]\r 21%|██        | 23/112 [00:03<00:14,  6.16it/s]\r 21%|██▏       | 24/112 [00:03<00:14,  6.16it/s]\r 22%|██▏       | 25/112 [00:04<00:14,  6.16it/s]\r 23%|██▎       | 26/112 [00:04<00:13,  6.16it/s]\r 24%|██▍       | 27/112 [00:04<00:13,  6.15it/s]\r 25%|██▌       | 28/112 [00:04<00:13,  6.16it/s]\r 26%|██▌       | 29/112 [00:04<00:13,  6.15it/s]\r 27%|██▋       | 30/112 [00:04<00:13,  6.15it/s]\r 28%|██▊       | 31/112 [00:05<00:13,  6.16it/s]\r 29%|██▊       | 32/112 [00:05<00:12,  6.16it/s]\r 29%|██▉       | 33/112 [00:05<00:12,  6.16it/s]\r 30%|███       | 34/112 [00:05<00:12,  6.16it/s]\r 31%|███▏      | 35/112 [00:05<00:12,  6.17it/s]\r 32%|███▏      | 36/112 [00:05<00:12,  6.17it/s]\r 33%|███▎      | 37/112 [00:06<00:12,  6.17it/s]\r 34%|███▍      | 38/112 [00:06<00:11,  6.17it/s]\r 35%|███▍      | 39/112 [00:06<00:11,  6.17it/s]\r 36%|███▌      | 40/112 [00:06<00:11,  6.16it/s]\r 37%|███▋      | 41/112 [00:06<00:11,  6.16it/s]\r 38%|███▊      | 42/112 [00:06<00:11,  6.16it/s]\r 38%|███▊      | 43/112 [00:07<00:11,  6.15it/s]\r 39%|███▉      | 44/112 [00:07<00:11,  6.15it/s]\r 40%|████      | 45/112 [00:07<00:10,  6.16it/s]\r 41%|████      | 46/112 [00:07<00:10,  6.15it/s]\r 42%|████▏     | 47/112 [00:07<00:10,  6.16it/s]\r 43%|████▎     | 48/112 [00:07<00:10,  6.16it/s]\r 44%|████▍     | 49/112 [00:08<00:10,  6.16it/s]\r 45%|████▍     | 50/112 [00:08<00:10,  6.16it/s]\r 46%|████▌     | 51/112 [00:08<00:09,  6.15it/s]\r 46%|████▋     | 52/112 [00:08<00:09,  6.15it/s]\r 47%|████▋     | 53/112 [00:08<00:09,  6.14it/s]\r 48%|████▊     | 54/112 [00:08<00:09,  6.12it/s]\r 49%|████▉     | 55/112 [00:08<00:09,  6.09it/s]\r 50%|█████     | 56/112 [00:09<00:09,  6.07it/s]\r 51%|█████     | 57/112 [00:09<00:09,  6.07it/s]\r 52%|█████▏    | 58/112 [00:09<00:08,  6.08it/s]\r 53%|█████▎    | 59/112 [00:09<00:08,  6.07it/s]\r 54%|█████▎    | 60/112 [00:09<00:08,  6.09it/s]\r 54%|█████▍    | 61/112 [00:09<00:08,  6.11it/s]\r 55%|█████▌    | 62/112 [00:10<00:08,  6.10it/s]\r 56%|█████▋    | 63/112 [00:10<00:08,  6.07it/s]\r 57%|█████▋    | 64/112 [00:10<00:07,  6.05it/s]\r 58%|█████▊    | 65/112 [00:10<00:07,  6.06it/s]\r 59%|█████▉    | 66/112 [00:10<00:07,  6.07it/s]\r 60%|█████▉    | 67/112 [00:10<00:07,  6.09it/s]\r 61%|██████    | 68/112 [00:11<00:07,  6.11it/s]\r 62%|██████▏   | 69/112 [00:11<00:07,  6.13it/s]\r 62%|██████▎   | 70/112 [00:11<00:06,  6.12it/s]\r 63%|██████▎   | 71/112 [00:11<00:06,  6.11it/s]\r 64%|██████▍   | 72/112 [00:11<00:06,  6.12it/s]\r 65%|██████▌   | 73/112 [00:11<00:06,  6.12it/s]\r 66%|██████▌   | 74/112 [00:12<00:06,  6.09it/s]\r 67%|██████▋   | 75/112 [00:12<00:06,  6.06it/s]\r 68%|██████▊   | 76/112 [00:12<00:05,  6.05it/s]\r 69%|██████▉   | 77/112 [00:12<00:05,  6.06it/s]\r 70%|██████▉   | 78/112 [00:12<00:05,  6.08it/s]\r 71%|███████   | 79/112 [00:12<00:05,  6.11it/s]\r 71%|███████▏  | 80/112 [00:13<00:05,  6.12it/s]\r 72%|███████▏  | 81/112 [00:13<00:05,  6.13it/s]\r 73%|███████▎  | 82/112 [00:13<00:04,  6.13it/s]\r 74%|███████▍  | 83/112 [00:13<00:04,  6.13it/s]\r 75%|███████▌  | 84/112 [00:13<00:04,  6.13it/s]\r 76%|███████▌  | 85/112 [00:13<00:04,  6.12it/s]\r 77%|███████▋  | 86/112 [00:14<00:04,  6.09it/s]\r 78%|███████▊  | 87/112 [00:14<00:04,  6.05it/s]\r 79%|███████▊  | 88/112 [00:14<00:03,  6.06it/s]\r 79%|███████▉  | 89/112 [00:14<00:03,  6.07it/s]\r 80%|████████  | 90/112 [00:14<00:03,  6.08it/s]\r 81%|████████▏ | 91/112 [00:14<00:03,  6.09it/s]\r 82%|████████▏ | 92/112 [00:15<00:03,  6.10it/s]\r 83%|████████▎ | 93/112 [00:15<00:03,  6.12it/s]\r 84%|████████▍ | 94/112 [00:15<00:02,  6.13it/s]\r 85%|████████▍ | 95/112 [00:15<00:02,  6.12it/s]\r 86%|████████▌ | 96/112 [00:15<00:02,  6.12it/s]\r 87%|████████▋ | 97/112 [00:15<00:02,  6.09it/s]\r 88%|████████▊ | 98/112 [00:16<00:02,  6.05it/s]\r 88%|████████▊ | 99/112 [00:16<00:02,  6.05it/s]\r 89%|████████▉ | 100/112 [00:16<00:01,  6.07it/s]\r 90%|█████████ | 101/112 [00:16<00:01,  6.08it/s]\r 91%|█████████ | 102/112 [00:16<00:01,  6.10it/s]\r 92%|█████████▏| 103/112 [00:16<00:01,  6.12it/s]\r 93%|█████████▎| 104/112 [00:17<00:01,  6.11it/s]\r 94%|█████████▍| 105/112 [00:17<00:01,  6.11it/s]\r 95%|█████████▍| 106/112 [00:17<00:00,  6.09it/s]\r 96%|█████████▌| 107/112 [00:17<00:00,  6.05it/s]\r 96%|█████████▋| 108/112 [00:17<00:00,  6.05it/s]\r 97%|█████████▋| 109/112 [00:17<00:00,  6.06it/s]\r 98%|█████████▊| 110/112 [00:18<00:00,  6.07it/s]\r 99%|█████████▉| 111/112 [00:18<00:00,  6.09it/s]\r100%|██████████| 112/112 [00:18<00:00,  6.14it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scores from data used for training...\nRunning POT with q=0.001, level=0.99..\nInitial threshold : 0.7201882004737854\nNumber of peaks : 283\nGrimshaw maximum log-likelihood estimation ... [done]\n\tγ = -0.016250451967990354\n\tσ = 0.2116042329432291\n\tL = 161.10851155849537\nExtreme quantile (probability = 0.001): 1.197853647367851\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/28479 [00:00<?, ?it/s]\r100%|██████████| 28479/28479 [00:00<00:00, 413234.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting anomalies based on POT-generated threshold - threshold value: 1.1979\nWithout point-adjustment, the F1-Score is: 0.4629\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With point-adjustment, the F1-Score is: 0.9002\n\nA total of 8 events were correctly identified. Here are the delays for each anomaly range:\n[((15849, 16394), 9), ((16963, 17516), 0), ((18071, 18527), 0), ((19367, 20087), 0), ((20786, 21194), 0), ((24679, 24681), 0), ((26114, 26115), 0), ((27554, 27555), 0)]\nThe average latency is 1.1250 timestamps.\nThe following events were not identified:\n[]\nPredicting anomalies based on epsilon-generated threshold - threshold value: 1.5960\nWithout point-adjustment, the F1-Score is: 0.3538\nWith point-adjustment, the F1-Score is: 0.9423\n\nA total of 8 events were correctly identified. Here are the delays for each anomaly range:\n[((15849, 16394), 27), ((16963, 17516), 0), ((18071, 18527), 0), ((19367, 20087), 0), ((20786, 21194), 0), ((24679, 24681), 0), ((26114, 26115), 0), ((27554, 27555), 0)]\nThe average latency is 3.3750 timestamps.\nThe following events were not identified:\n[]\nInitiating Brute-force method for best F1...\nWithout point-adjustment, the best achievable F1-Score is: 0.5862\nThis is achieved by setting the threshold at: 0.7393\n\nThe corresponding point-adjusted F1-Score is: 0.7439\n\nA total of 8 events were correctly identified. Here are the delays for each anomaly range:\n[((15849, 16394), 1), ((16963, 17516), 0), ((18071, 18527), 0), ((19367, 20087), 0), ((20786, 21194), 0), ((24679, 24681), 0), ((26114, 26115), 0), ((27554, 27555), 0)]\nThe average latency is 0.1250 timestamps.\nThe following events were not identified:\n[]\nInitiating Brute-force method for best point-adjusted F1...\nWithout point-adjustment, the best achievable F1-Score is: 0.1770\nThis is achieved by setting the threshold at: 2.9026\n\nThe corresponding point-adjusted F1-Score is: 0.9991\n\nA total of 8 events were correctly identified. Here are the delays for each anomaly range:\n[((15849, 16394), 27), ((16963, 17516), 1), ((18071, 18527), 0), ((19367, 20087), 1), ((20786, 21194), 0), ((24679, 24681), 1), ((26114, 26115), 0), ((27554, 27555), 0)]\nThe average latency is 3.7500 timestamps.\nThe following events were not identified:\n[]\nFinished.\n"
     ]
    }
   ],
   "source": [
    "run_id = get_run_id(run_name, f\"/Experiments/{dataset}_training\")\n",
    "\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "\n",
    "    art_uri = mlflow.get_artifact_uri()\n",
    "\n",
    "    # Get configs used for model training\n",
    "    print(f'Using model from run with ID: {run_id}')\n",
    "    \n",
    "    model_args = mlflow.artifacts.load_dict(art_uri+\"/config.txt\")\n",
    "\n",
    "    window_size = model_args['window_size']\n",
    "\n",
    "    # --------------------------- START EVALUATION -----------------------------\n",
    "    # Get data from the dataset\n",
    "    (x_eval, y_eval) = get_data(dataset, mode=\"eval\", start=eval_start, end=eval_end)\n",
    "\n",
    "    # This workaround needs to happen internally at the moment\n",
    "    # We must use the last window_size timestamps from training as the first window_size timestamps\n",
    "    # for evaluation, due to the sliding window framework\n",
    "    x_train, _ = get_data(dataset, mode=\"train\", start=-window_size, end=None)\n",
    "    x_eval = np.concatenate((x_train, x_eval), axis=0)\n",
    "\n",
    "    # Cast data into tensor objects\n",
    "    x_eval = torch.from_numpy(x_eval).float()\n",
    "    n_features = x_eval.shape[1]\n",
    "\n",
    "    # We want to perform forecasting/reconstruction on all features\n",
    "    out_dim = n_features\n",
    "\n",
    "    # Construct dataset from tensor objects - no stride here\n",
    "    eval_dataset = SlidingWindowDataset(x_eval, window_size)\n",
    "\n",
    "    print(\"Evaluating:\")\n",
    "    # Create the data loader - no shuffling here\n",
    "    eval_loader, _ = create_data_loader(eval_dataset, model_args['batch_size'], None, False)\n",
    "\n",
    "    # Load the model\n",
    "    model = mlflow.pytorch.load_model(f\"{art_uri}/{dataset}_model\")\n",
    "\n",
    "    # Initialize the Handler module\n",
    "    handler = Handler(\n",
    "        model=model,\n",
    "        optimizer=None,\n",
    "        scheduler=None,\n",
    "        window_size=window_size,\n",
    "        n_features=n_features,\n",
    "        batch_size=model_args['batch_size'],\n",
    "        n_epochs=None,\n",
    "        patience=None,\n",
    "        forecast_criterion=None,\n",
    "        recon_criterion=None,\n",
    "        use_cuda=use_cuda,\n",
    "        print_every=None,\n",
    "        gamma=model_args['gamma']\n",
    "    )\n",
    "\n",
    "    # Get new scores\n",
    "    print(\"Calculating scores on evaluation data...\")\n",
    "    new_scores, df = handler.score(loader=eval_loader, details=show_details)\n",
    "\n",
    "    # Save a dataframe with per-feature predictions and scores for debugging\n",
    "    if show_details:\n",
    "        df.to_pickle('per_feat_scores.pkl')\n",
    "        mlflow.log_artifact('per_feat_scores.pkl')\n",
    "        os.remove('per_feat_scores.pkl')\n",
    "\n",
    "        mlflow.log_dict({'eval_scores':new_scores.tolist()}, \"eval_scores.json\")\n",
    "\n",
    "    # --> POT threshold\n",
    "    \n",
    "    print(\"Loading scores from data used for training...\")\n",
    "    \n",
    "    train_scores = json_to_numpy(art_uri+\"/anom_scores.json\")\n",
    "\n",
    "    if use_mov_av:\n",
    "        smoothing_window = int(model_args['batch_size'] * window_size * 0.05)\n",
    "        train_scores = pd.DataFrame(train_scores).ewm(span=smoothing_window).mean().values.flatten()\n",
    "        new_scores = pd.DataFrame(new_scores).ewm(span=smoothing_window).mean().values.flatten()\n",
    "\n",
    "    pot_thresh = pot_threshold(train_scores, new_scores, q=q, level=level, dynamic=dynamic_pot)\n",
    "\n",
    "    print(f\"Predicting anomalies based on POT-generated threshold - threshold value: {pot_thresh:.4f}\")\n",
    "\n",
    "    # Make predictions based on threshold\n",
    "    pot_anoms = handler.predict(new_scores, pot_thresh)\n",
    "\n",
    "    # Perform evaluation based on predictions\n",
    "    f1_pot, prec_pot, rec_pot = get_metrics(pot_anoms, y_eval)\n",
    "    \n",
    "    # Get delays\n",
    "    pot_correct, pot_delay, pot_identified, pot_unidentified = calculate_latency(y_eval, pot_anoms)\n",
    "\n",
    "    print(f\"Without point-adjustment, the F1-Score is: {f1_pot:.4f}\")\n",
    "\n",
    "    # Same evaluation, but with point adjustment\n",
    "    pa_pot_anoms = PA(y_eval, pot_anoms)\n",
    "    pa_f1_pot, pa_prec_pot, pa_rec_pot = get_metrics(pa_pot_anoms, y_eval)\n",
    "\n",
    "    print(f\"With point-adjustment, the F1-Score is: {pa_f1_pot:.4f}\\n\")\n",
    "    print(f\"A total of {pot_correct} events were correctly identified. Here are the delays for each anomaly range:\")\n",
    "    print(pot_identified)\n",
    "    print(f\"The average latency is {pot_delay:.4f} timestamps.\")\n",
    "    print(\"The following events were not identified:\")\n",
    "    print(pot_unidentified)\n",
    "\n",
    "    update_json(art_uri, \"thresholds.json\", {\"POT\": pot_thresh})\n",
    "\n",
    "    mlflow.log_metric(key=\"POT_F1\", value=f1_pot)\n",
    "    mlflow.log_metric(key=\"POT_F1-PA\", value=pa_f1_pot)\n",
    "\n",
    "    # --> epsilon threshold\n",
    "\n",
    "    thresholds = mlflow.artifacts.load_dict(art_uri+\"/thresholds.json\")\n",
    "    e_thresh = thresholds[\"epsilon\"]\n",
    "\n",
    "    print(f\"Predicting anomalies based on epsilon-generated threshold - threshold value: {e_thresh:.4f}\")\n",
    "\n",
    "    # Make predictions based on threshold\n",
    "    e_anoms = handler.predict(new_scores, e_thresh)\n",
    "\n",
    "    # Perform evaluation based on predictions\n",
    "    f1_e, prec_e, rec_e = get_metrics(e_anoms, y_eval)\n",
    "    \n",
    "    # Get delays\n",
    "    e_correct, e_delay, e_identified, e_unidentified = calculate_latency(y_eval, e_anoms)\n",
    "\n",
    "    print(f\"Without point-adjustment, the F1-Score is: {f1_e:.4f}\")\n",
    "\n",
    "    # Same evaluation, but with point adjustment\n",
    "    pa_e_anoms = PA(y_eval, e_anoms)\n",
    "    pa_f1_e, pa_rec_e, pa_prec_e = get_metrics(pa_e_anoms, y_eval)\n",
    "\n",
    "    print(f\"With point-adjustment, the F1-Score is: {pa_f1_e:.4f}\\n\")\n",
    "    print(f\"A total of {e_correct} events were correctly identified. Here are the delays for each anomaly range:\")\n",
    "    print(e_identified)\n",
    "    print(f\"The average latency is {e_delay:.4f} timestamps.\")\n",
    "    print(\"The following events were not identified:\")\n",
    "    print(e_unidentified)\n",
    "\n",
    "    mlflow.log_metric(key=\"Epsilon_F1\", value=f1_e)\n",
    "    mlflow.log_metric(key=\"Epsilon_F1-PA\", value=pa_f1_e)\n",
    "\n",
    "    # --> Brute-force threshold (Best F1)\n",
    "\n",
    "    print(\"Initiating Brute-force method for best F1...\")\n",
    "\n",
    "    thresholds = np.linspace(min(new_scores), max(new_scores), 200)\n",
    "    bf_res, pa_bf_res = [], []\n",
    "    for bf_thresh in thresholds:\n",
    "        anoms = handler.predict(new_scores, bf_thresh)\n",
    "        # Get F1-Score without PA\n",
    "        f1, prec, rec = get_metrics(anoms, y_eval)\n",
    "        bf_res.append(f1)\n",
    "        # Get F1-Score with PA\n",
    "        pa_anoms = PA(y_eval, anoms)\n",
    "        f1, prec, rec = get_metrics(pa_anoms, y_eval)\n",
    "        pa_bf_res.append(f1)\n",
    "    \n",
    "    best_idx = bf_res.index(max(bf_res))\n",
    "    bf_thresh = thresholds[best_idx]\n",
    "\n",
    "    # Run one last time\n",
    "    bf_anoms = handler.predict(new_scores, bf_thresh)\n",
    "    f1_bf, prec_bf, rec_bf = get_metrics(bf_anoms, y_eval)\n",
    "    \n",
    "    # Get delays\n",
    "    bf_correct, bf_delay, bf_identified, bf_unidentified = calculate_latency(y_eval, bf_anoms)\n",
    "    \n",
    "    print(f\"Without point-adjustment, the best achievable F1-Score is: {f1_bf:.4f}\")\n",
    "    print(f\"This is achieved by setting the threshold at: {bf_thresh:.4f}\\n\")\n",
    "    \n",
    "    pa_bf_anoms = PA(y_eval, bf_anoms)\n",
    "    pa_f1_bf, pa_rec_bf, pa_prec_bf = get_metrics(pa_bf_anoms, y_eval)\n",
    "\n",
    "    print(f\"The corresponding point-adjusted F1-Score is: {pa_f1_bf:.4f}\\n\")\n",
    "    print(f\"A total of {bf_correct} events were correctly identified. Here are the delays for each anomaly range:\")\n",
    "    print(bf_identified)\n",
    "    print(f\"The average latency is {bf_delay:.4f} timestamps.\")\n",
    "    print(\"The following events were not identified:\")\n",
    "    print(bf_unidentified)\n",
    "\n",
    "    update_json(art_uri, \"thresholds.json\", {\"BF-F1\": bf_thresh})\n",
    "\n",
    "    mlflow.log_metric(key=\"Brute_Force_F1\", value=f1_bf)\n",
    "    mlflow.log_metric(key=\"Brute_Force_F1-PA\", value=pa_f1_bf)\n",
    "    \n",
    "    # --> Brute-force threshold (Best adjusted F1)\n",
    "\n",
    "    print(\"Initiating Brute-force method for best point-adjusted F1...\")\n",
    "    \n",
    "    pa_best_idx = pa_bf_res.index(max(pa_bf_res))\n",
    "    pa_bf_thresh = thresholds[pa_best_idx]\n",
    "    \n",
    "    # Run one last time\n",
    "    bf_anoms_2 = handler.predict(new_scores, pa_bf_thresh)\n",
    "    f1_bf_2, prec_bf_2, rec_bf_2 = get_metrics(bf_anoms_2, y_eval)\n",
    "    \n",
    "    # Get delays\n",
    "    bf_correct_2, bf_delay_2, bf_identified_2, bf_unidentified_2 = calculate_latency(y_eval, bf_anoms_2)\n",
    "    \n",
    "    print(f\"Without point-adjustment, the best achievable F1-Score is: {f1_bf_2:.4f}\")\n",
    "    print(f\"This is achieved by setting the threshold at: {pa_bf_thresh:.4f}\\n\")\n",
    "    \n",
    "    pa_bf_anoms_2 = PA(y_eval, bf_anoms_2)\n",
    "    pa_f1_bf_2, pa_rec_bf_2, pa_prec_bf_2 = get_metrics(pa_bf_anoms_2, y_eval)\n",
    "\n",
    "    print(f\"The corresponding point-adjusted F1-Score is: {pa_f1_bf_2:.4f}\\n\")\n",
    "    print(f\"A total of {bf_correct_2} events were correctly identified. Here are the delays for each anomaly range:\")\n",
    "    print(bf_identified_2)\n",
    "    print(f\"The average latency is {bf_delay_2:.4f} timestamps.\")\n",
    "    print(\"The following events were not identified:\")\n",
    "    print(bf_unidentified_2)\n",
    "\n",
    "    update_json(art_uri, \"thresholds.json\", {\"BF-F1-PA\": pa_bf_thresh})\n",
    "\n",
    "    mlflow.log_metric(key=\"PA_Brute_Force_F1\", value=f1_bf_2)\n",
    "    mlflow.log_metric(key=\"PA_Brute_Force_F1-PA\", value=pa_f1_bf_2)\n",
    "\n",
    "    # ---------------------------- END EVALUATION ------------------------------\n",
    "\n",
    "    # save results\n",
    "    with open('eval_summary.txt', 'w') as f:\n",
    "\n",
    "        lines_to_write = [\n",
    "            \"POT algorithm:\\n\",\n",
    "            f\"Threshold: {pot_thresh:.4f}\\n\",\n",
    "            f\"Without PA:\\t F1-Score: {f1_pot*100:.4f}%, \\t Recall: {rec_pot*100:.4f}%, \\t Precision: {prec_pot*100:.4f}%\\n\",\n",
    "            f\"With PA:\\t {pa_f1_pot*100:.4f}%, \\t Recall: {pa_rec_pot*100:.4f}%, \\t Precision: {pa_prec_pot*100:.4f}%\\n\",\n",
    "            f\"Identified Events & Latencies: {pot_identified}\\n\",\n",
    "            f\"Average Latency: {pot_delay} timestamps\\n\",\n",
    "            f\"Unidentified Events: {pot_unidentified}\\n\\n\\n\",\n",
    "            \"epsilon algorithm:\\n\",\n",
    "            f\"Threshold: {e_thresh:.4f}\\n\",\n",
    "            f\"Without PA:\\t F1-Score: {f1_e*100:.4f}%, \\t Recall: {rec_e*100:.4f}%, \\t Precision: {prec_e*100:.4f}%\\n\",\n",
    "            f\"With PA:\\t {pa_f1_e*100:.4f}%, \\t Recall: {pa_rec_e*100:.4f}%, \\t Precision: {pa_prec_e*100:.4f}%\\n\",\n",
    "            f\"Identified Events & Latencies: {e_identified}\\n\",\n",
    "            f\"Average Latency: {e_delay} timestamps\\n\",\n",
    "            f\"Unidentified Events: {e_unidentified}\\n\\n\\n\",\n",
    "            \"Brute force for best F1:\\n\",\n",
    "            f\"Threshold: {bf_thresh:.4f}\\n\"\n",
    "            f\"Without PA:\\t F1-Score: {f1_bf*100:.4f}%, \\t Recall: {rec_bf*100:.4f}%, \\t Precision: {prec_bf*100:.4f}%\\n\",\n",
    "            f\"With PA:\\t {pa_f1_bf*100:.4f}%, \\t Recall: {pa_rec_bf*100:.4f}%, \\t Precision: {pa_prec_bf*100:.4f}%\\n\",\n",
    "            f\"Identified Events & Latencies: {bf_identified}\\n\",\n",
    "            f\"Average Latency: {bf_delay} timestamps\\n\",\n",
    "            f\"Unidentified Events: {bf_unidentified}\\n\\n\\n\",\n",
    "            \"Brute force for best point-adjusted F1:\\n\",\n",
    "            f\"Threshold: {pa_bf_thresh:.4f}\\n\"\n",
    "            f\"Without PA:\\t F1-Score: {f1_bf_2*100:.4f}%, \\t Recall: {rec_bf_2*100:.4f}%, \\t Precision: {prec_bf_2*100:.4f}%\\n\",\n",
    "            f\"With PA:\\t {pa_f1_bf_2*100:.4f}%, \\t Recall: {pa_rec_bf_2*100:.4f}%, \\t Precision: {pa_prec_bf_2*100:.4f}%\\n\",\n",
    "            f\"Identified Events & Latencies: {bf_identified_2}\\n\",\n",
    "            f\"Average Latency: {bf_delay_2} timestamps\\n\",\n",
    "            f\"Unidentified Events: {bf_unidentified_2}\\n\\n\\n\"\n",
    "        ]\n",
    "\n",
    "        f.writelines(lines_to_write)\n",
    "\n",
    "    mlflow.log_artifact('eval_summary.txt')\n",
    "    os.remove('eval_summary.txt')\n",
    "\n",
    "    # Also log the ground truth labels, to be used with the Streamlit external UI\n",
    "    mlflow.log_dict({'labels':y_eval.tolist()}, \"labels.json\")\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b05711f0-842f-449b-a87d-23d0a29f2aaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4,
    "widgetLayout": [
     {
      "breakBefore": false,
      "name": "dataset",
      "width": 90
     },
     {
      "breakBefore": false,
      "name": "eval_start",
      "width": 90
     },
     {
      "breakBefore": false,
      "name": "eval_end",
      "width": 90
     },
     {
      "breakBefore": false,
      "name": "run_name",
      "width": 90
     },
     {
      "breakBefore": false,
      "name": "use_cuda",
      "width": 90
     },
     {
      "breakBefore": false,
      "name": "show_details",
      "width": 90
     },
     {
      "breakBefore": false,
      "name": "threshold",
      "width": 90
     },
     {
      "breakBefore": false,
      "name": "use_mov_av",
      "width": 90
     },
     {
      "breakBefore": false,
      "name": "q",
      "width": 90
     },
     {
      "breakBefore": false,
      "name": "level",
      "width": 90
     },
     {
      "breakBefore": false,
      "name": "dynamic_pot",
      "width": 90
     }
    ]
   },
   "notebookName": "evaluate",
   "widgets": {
    "dataset": {
     "currentValue": "system_1",
     "nuid": "f649f204-b6ce-4268-8b97-8634467d838c",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "system_1",
      "label": null,
      "name": "dataset",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "dynamic_pot": {
     "currentValue": "False",
     "nuid": "ad96eaca-e8fd-4771-976b-576cbdc1508b",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "False",
      "label": null,
      "name": "dynamic_pot",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "eval_end": {
     "currentValue": "None",
     "nuid": "05e8c906-8529-42c2-b32d-f4df32064e4b",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "None",
      "label": null,
      "name": "eval_end",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "eval_start": {
     "currentValue": "0",
     "nuid": "ed9f0b4b-4651-4268-af73-01ebf86952dd",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "0",
      "label": null,
      "name": "eval_start",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "level": {
     "currentValue": "0.99",
     "nuid": "9ca9263b-0c97-42ce-8e3b-54cb9467018e",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "0.99",
      "label": null,
      "name": "level",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "q": {
     "currentValue": "0.001",
     "nuid": "1d362204-1972-49f6-91ab-1e5cb17421b4",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "0.001",
      "label": null,
      "name": "q",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "run_name": {
     "currentValue": "-1",
     "nuid": "3194e3b6-f30d-48fd-9654-a175709343da",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "-1",
      "label": null,
      "name": "run_name",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "show_details": {
     "currentValue": "True",
     "nuid": "b4103e9e-51b4-428c-938d-ed96e6174d7f",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "True",
      "label": null,
      "name": "show_details",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "threshold": {
     "currentValue": "POT",
     "nuid": "a3984200-821a-471c-9ff1-3f6cf707339a",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "POT",
      "label": null,
      "name": "threshold",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "use_cuda": {
     "currentValue": "True",
     "nuid": "f1b62eae-0003-4222-a5c4-e24760bc13e6",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "True",
      "label": null,
      "name": "use_cuda",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "use_mov_av": {
     "currentValue": "False",
     "nuid": "184de99a-d7b1-4058-af74-439a3942290e",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "False",
      "label": null,
      "name": "use_mov_av",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
